\section{Discussion}
\label{sec:concl}
In the paper, we described a novel high-dimensional generalized additive model with Bayesian hierarchical prior for the purpose of predictive modeling. In particular, we introduce a two-part spike-and-slab LASSO prior for reparameterized smooth functions and derive a scalable EM-CD algorithm for model fitting. The proposed model provides a new angle to address the excess shrinkage of smooth functions that is commonly vulnerable to previous regularized high-dimensional GAMs, and hence improves the predictive performance. Th EM-CD algorithm, extended from previous spike-and-slab LASSO models, provides a computationally efficient alternative to the computational prohibitive MCMC algorithms, enhancing the scalability of spike-and-slab models. In addition, the two-part prior motivates the bi-level selection of predictors, selection of linear and nonlinear components. In the simulation study and real-data analyses, the proposed model demonstrates improvement in prediction and computational advantage when compared to the state-of-the-art models. When serving the purpose of variable selection, trade-offs exist among methods of comparison. We implement the proposed model in an open-source R package \texttt{BHAM}, deposited at [https://github.com/boyiguo1/BHAM](https://github.com/boyiguo1/BHAM). To maximize the flexibility of smooth function specification, we deploy the same programming grammar as in the state-of-the-art package \texttt{mgcv}, in contrast to previous tools where smooth functions are limited to the default ones. Ancillary functions are provided for model specification in high-dimensional settings, curve plotting and functional selection.

The proposed model shares many commonalities with the SB-GAM [@Bai2021], which is independently developed around the same time as the proposed work. Both frameworks emphasize computational efficiency by deploying group spike-and-slab LASSO type priors and optimization-based scalable algorithms. Bai provides the theoretical proof for the consistency of variable selection using group spike-and-slab LASSO prior. The proposed model focuses on improving prediction performance for high-dimensional GAM, with the capability of bi-level selection. Moreover, the proposed model can easily generalize to other families of priors and smooth functions if desired. Not focused in this manuscript, the generalization is described in the Supporting Information. 

During designing and analyzing the simulation study, we made couple of interesting observations. First of all, variable selection is a delicate topic in the context of predictive modeling. When prediction performance is used to tune a model, the model could possibly include noise variables in models, for example LASSO and LASSO-based models. \cite{Wu2019} Moreover, bi-level selection is a more complex problem than variable selection. The complexity shows on the validity of the effect hierarchy principle. While most functional forms follow that the linear component exists in the nonlinear function, there are functions that don't follow it, e.g. $x^2$. The proposed prior and spikeSlabGAM employ different structures: the proposed prior imposes effect hierarchy while spikeSlabGAM treats the selection of linear and nonlinear components independent. The different prior setups lead to trade-offs for the purpose of bi-level selection. We recommend to use more judgment in bi-level selection, either relying on heuristic knowledge to choose appropriate prior or exploring multiple models when heuristic knowledge doesn't exist. Secondly, we find the performance of the proposed model is more sensitive to the granularity of $s_0$ sequence in the high-dimensional settings than in the lower dimension settings. Even though the current default sequence of $s_0$ can result in reasonable performance shown in the simulation studies, we recommend fine-tuning the model with a granular sequence of $s_0$ for performance improvement.

<!-- There are some improvements possible for the proposed models. First of all, the proposed model achieves a bi-level selection via the two-part spike-and-slab spline prior. Nevertheless, this set-up could result in a situation that is not theoretically sound: the nonlinear component is selected, but the linear component is not. We currently address it analytically by including the linear component in the model when nonlinear component is selected. Another possible solution is to impose a dependent structure of $\gamma_{j}^\tp$ on $\gamma_{j^{0}}$, i.e. $\gamma_j^\tp|\gamma_{j}^{0}, \theta_j$. Secondly, the computational time for fitting a BHAM model with EM-IWLS algorithms can be improved. Current implementation of the EM-IWLS algorithm jointly updates all coefficients in each iteration, which requires a lot computation resources. This jointly updating procedure can be enhanced by adapting a backfitting step [@Hastie1987] where each smooth function are updated individually. Thirdly, when using the proposed model in real data analysis where a screening procedure is implemented before joint predictive modeling. we recommend to include the screening procedure in the cross-validation during model selection. [@Friedman2017] For the sake of model comparison, we fit the models using the same pool of predictors in Section \ref{sec:ECB}. -->

Our future efforts are direct to uncertainty inference of the proposed model, survival analysis and integrative analysis. Using EM-CD algorithm to fit the proposed BHAM is incapable of conducting uncertainty inference. We derive the EM-Iterative Weighted Least Square algorithm (EM-IWLS, see the Supporting Information) as an alternative. Instead of the Coordinate Descent algorithm, we use the Iterative Weighted Least Square algorithm in the EM procedure. The EM-IWLS algorithm is previously used to fit Bayesian high-dimensional generalized linear models \cite{Yi2012}, and deliver estimates of the coefficient variance-covariance matrix. Due to the space limit, technical details will be explained in a future manuscript. While the proposed model addresses a great deal of analytic problems, analyzing the time-to-event outcome remains unsolved. A naive approach would be convert a time-to-event outcome to a Poisson outcome following Whitehead [@Whitehead1980]. However, it would be more efficient to directly fit Cox models via penalized pseudo likelihood function [@Simon2011]. Meanwhile, with the growing understanding of biological structure within -omics field, it is appealing to integrate external biology information in the modeling process. The main motivation for integrative models is that biologically informed grouping of weak effects increases the power of detecting true associations between features and the outcome [@Peterson2016], and stabilizes the analysis results for reproducibility purposes. Such integration can be achieved by setting up a structural hyperprior on the inclusion indicator of the smooth function null space $\bs \gamma^0$. A similar strategy has been used in Ferrari and Dunson [@Ferrari2020].


