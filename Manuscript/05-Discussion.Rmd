\section{Discussion}
\label{sec:concl}
\bg{In the paper, we described a novel high-dimensional generalized additive model with Bayesian hierarchical prior for the purpose of predictive modelling. In particular, we introduce a two-part spike-and-slab LASSO prior for reparameterized smoothing function and derive a scalable EM-CD algorithm for model fitting. The proposed model provides a new angle to address the excess shrinkage of smoothing functions that is commonly vulnerable to previous regularized high-dimensional GAMs, and hence improves the predictive performance. Th EM-CD algorithm, extended from previous spike-and-slab LASSO models, provides a computationally efficient alternative to the computational prohibitive MCMC algorithms, enhancing the scalability of spike-and-slab models. In addition, the two-part prior motivates the bi-level selection of predictors, selection of linear and nonlinear component. In the simulation study and real-data analyses, the proposed model demonstrates improvement in prediction and computational advantage when compared to the state-of-the-art models. When serving the purpose of variable selection, trade-offs exist among methods of comparison.} We implement the proposed model in an open-source R package \texttt{BHAM}, deposited at [https://github.com/boyiguo1/BHAM](https://github.com/boyiguo1/BHAM). To maximize the flexibility of smoothing function specification, we deploy the same programming grammar as in the state-of-the-art package \texttt{mgcv}, in contrast to previous tools where smoothing functions are limited to the default ones. Ancillary functions are provided for model specification in high-dimensional settings, curve plotting and functional selection.

The proposed model shares many commonality with the SB-GAM [@Bai2021], independently developed around the same time of the proposed work. Both frameworks emphasize computational efficiency by deploying group spike-and-slab LASSO type priors and optimization-based scalable algorithms. Bai provides the theoretical proof for the consistency of variable selection using group spike-and-slab LASSO prior. \bg{The proposed model focuses on improving prediction performance for high-dimensional GAM, with the capability of bi-level selection. Moreover, the proposed model can easily generalize to other family of priors or other family of smoothing functions if desired. Not focused in this manuscript, the generalization is described in the supporting materials.} 

\bg{During designing and analyzing the simulation study, we made couple interesting observations. First of all, variable selection is a delicate topic in the context predictive modelling. When prediction performance is used to tune a model, the model could possibly include noise variable in models, for example LASSO and LASSO-based models. \cite{Wu2019} Moreover, bi-level selection is a more complex problem than variable selection. The complexity reflects on the validity of the effect hierarchy principle. While most functional forms follow that linear components exists in the nonlinear function, there are functions that don't follow it, e.g. $x^2$. The proposed prior and spikeSlabGAM employ different structure: the proposed prior imposes effect hierarchy while spikeSlabGAM treats the selection of linear and nonlinear components independent. The different prior setups lead to trade-offs for the purpose of bi-level selection. We recommend to use more judgement in bi-level selection, either relying on heuristic knowledge to choose appropriate prior or exploring multiple models when heuristic knowledge doesn't exist. Secondly, we find the performance of the proposed model are more sensitive to the granularity of $s_0$ sequence in the high-dimensional settings than in the lower dimension settings. Even though the current default sequence of $s_0$ can result in reasonable performance shown in the simulation studies, we recommend to fine-tune the model with granular sequence of $s_0$ for performance improvement.}

<!-- There are some improvements possible for the proposed models. First of all, the proposed model achieves a bi-level selection via the two-part spike-and-slab spline prior. Nevertheless, this set-up could result in a situation that is not theoretically sound: the non-linear component is selected, but the linear component is not. We currently address it analytically by including the linear component in the model when non-linear component is selected. Another possible solution is to impose a dependent structure of $\gamma_{j}^\tp$ on $\gamma_{j^{0}}$, i.e. $\gamma_j^\tp|\gamma_{j}^{0}, \theta_j$. Secondly, the computational time for fitting a BHAM model with EM-IWLS algorithms can be improved. Current implementation of the EM-IWLS algorithm jointly updates all coefficients in each iteration, which requires a lot computation resources. This jointly updating procedure can be enhanced by adapting a backfitting step [@Hastie1987] where each smoothing function are updated individually. Thirdly, when using the proposed model in real data analysis where a screening procedure is implemented before joint predictive modeling. we recommend to include the screening procedure in the cross-validation during model selection. [@Friedman2017] For the sake of model comparison, we fit the models using the same pool of predictors in Section \ref{sec:ECB}. -->

Our future efforts direct to survival analysis and integrative analysis. While the proposed model addresses a great deal of analytic problem, analyzing the time-to-event outcome remains unsolved. An naive approach would be convert a time-to-event outcome to a Poisson outcome following Whitehead [@Whitehead1980]. However, it would be more efficient to directly fit Cox models via penalized pseudo likelihood function [@Simon2011]. Meanwhile, with growing understanding of biological structure within -omics field, it is appealing to integrate external biology information in the modeling process. The main motivation for integrative models is that biologically informed grouping of weak effects increases the power of detecting true associations between features and the outcome [@Peterson2016], and stabilizes the analysis results for reproducibility purpose. Such integration can be achieved by setting up a structural hyperprior on the inclusion indicator of the smoothing function null space $\bs \gamma^0$. The similar strategy has been used in Ferrari and Dunson [@Ferrari2020].


