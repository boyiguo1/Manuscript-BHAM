\begin{table}[ht]
\centering
\begin{tabular}{cccccccc}
  \hline
P & mgcv & LASSO & COSSO & Adaptive COSSO & BHAM & SB-GAM & spikeSlabGAM \\ 
  \hline
  4 & 0.38 (0.01) & 0.39 (0.01) & 0.31 (0.08) & 0.29 (0.11) & 0.38 (0.01) & 0.35 (0.01) & 0.39 (0.01) \\ 
   10 & 0.36 (0.02) & 0.38 (0.01) & 0.35 (0.03) & 0.34 (0.04) & 0.39 (0.01) & 0.33 (0.02) & 0.39 (0.01) \\ 
   50 & 0.09 (0.09) & 0.37 (0.01) & 0.30 (0.06) & 0.30 (0.36) & 0.38 (0.01) & 0.32 (0.03) & 0.37 (0.01) \\ 
  100 & NaN (NA) & 0.37 (0.01) & 0.28 (0.07) & 0.34 (0.04) & 0.38 (0.01) & 0.29 (0.07) & 0.35 (0.01) \\ 
  200 & NaN (NA) & 0.36 (0.01) & 0.26 (0.08) & 0.31 (0.06) & 0.38 (0.03) & 0.28 (0.06) & 0.33 (0.02) \\ 
   \hline
\end{tabular}
\caption{The average and standard deviation of the out-of-sample $R^2$ measure for
    Gaussian outcomes over 50 iterations. The models of comparison include the proposed Bayesian
    hierarchical additive model (BHAM) fitted with Iterative Weighted Least Square (BHAM-IWLS) and
    Coordinate Descent (BHAM-CD) algorithms, component selection and smoothing operator (COSSO), adaptive
    COSSO, mgcv and sparse Bayesian generalized additive model (SB-GAM). mgcv doesn't provide estimation
    whe number of parameters exceeds sample size i.e. p = 100, 200.} 
\label{tab:lnr_gaus}
\end{table}
