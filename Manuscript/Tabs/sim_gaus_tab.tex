\begin{table}[ht]
\centering
\begin{tabular}{cccccccc}
  \hline
P & mgcv & LASSO & COSSO & Adaptive COSSO & BHAM & SB-GAM & spikeSlabGAM \\ 
  \hline
  4 & 0.90 (0.01) & 0.33 (0.01) & 0.71 (0.13) & 0.72 (0.11) & 0.90 (0.01) & 0.79 (0.04) & 0.80 (0.00) \\ 
   10 & 0.90 (0.01) & 0.33 (0.01) & 0.66 (0.21) & 0.77 (0.02) & 0.89 (0.01) & 0.79 (0.04) & 0.79 (0.00) \\ 
   50 & 0.86 (0.02) & 0.32 (0.01) & 0.46 (0.19) & 0.57 (0.18) & 0.80 (0.02) & 0.78 (0.05) & 0.78 (0.01) \\ 
  100 & - & 0.32 (0.01) & 0.41 (0.23) & 0.48 (0.25) & 0.79 (0.01) & 0.79 (0.05) & 0.77 (0.01) \\ 
  200 & - & 0.32 (0.01) & 0.39 (0.19) & 0.40 (0.17) & 0.79 (0.01) & 0.78 (0.04) & 0.75 (0.01) \\ 
   \hline
\end{tabular}
\caption{The average and standard deviation of the out-of-sample $R^2$ measure for
    Gaussian outcomes over 50 iterations. The models of comparison include the proposed
    Bayesian hierarchical additive model (BHAM), linear LASSO model (LASSO), component
    selection and smoothing operator (COSSO), adaptive COSSO, mgcv, sparse Bayesian
    generalized additive model (SB-GAM), and spikeSlabGAM mdoel. mgcv doesn't provide estimation
    whe number of parameters exceeds sample size i.e. p = 100, 200.} 
\label{tab:gaus}
\end{table}
