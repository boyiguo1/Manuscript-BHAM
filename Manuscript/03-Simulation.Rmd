# Simulation Study
\label{sec:sim}

In this section, we compare the performance of the proposed models to four alternative models: component selection and smoothing operator (COSSO) [@Zhang2006GAM], adaptive COSSO [@Storlie2011], generalized additive models with automatic smoothing [@Wood2011], SB-GAM [@Bai2021]. COSSO is one of the earliest smoothing spline models that consider sparsity-smoothness penalty. Adaptive COSSO improved upon COSSO by using adaptive weight for penalties such that the penalty of each functional component are different for extra flexibility. Generalized additive models with automatic smoothing, hereafter \textit{mgcv}, is one of the most popular models for nonlinear effect interpolation and prediction. SB-GAM is the first spike-and-slab lasso GAM. We implement COSSO and adaptive COSSO with R package \texttt{cosso 2.1-1}, generalized additive models with automatic smoothing with R package \texttt{mgcv 1.8-31}, SB-GAM with R package \texttt{sparseGAM 1.0}. COSSO models and SB-GAM do not provide flexibility to define smoothing functions, and hence use the default choices. Both mgcv and proposed models allow customized smoothing functions and we choose the cubic regression spline. We controll the dimensionality of each smoothing function, 10 bases, for all different choices of smoothing functions. We use 5-fold CV with the default selection criteria to select the final model for COSSO models, SB-GAM and the proposed models. 20 default candidates of tuning parameters ($s_0$ in BHAM, $\lambda_0$ in SB-GAM) are examined for SB-GAM and the proposed models which allow user-specification of tuning candidates. All computation was conducted on a high-performance 64-bit Linux platform with 48 cores of 2.70GHz eight-core Intel Xeon E5-2680 processors and 24G of RAM per core and R 3.6.2 [@R].

Other related methods for high-dimensional GAMs also exist, notably the methods of sparse additive models by Ravikumar et al. [@Ravikumar2009] and stochastic search term selection for GAM [@Scheipl2012]. However, we exclude these methods from current simulation study because of demonstrated inferior predictive performance compared to mgcv and scalability issues with increased number of predictors. [@Scheipl2013]


## Monte Carlo Simulation Study
We follow the data generating process described in Bai [@Bai2021]. We first generate $n=500$ training data points with $p=4, 10, 50, 100, 200$ predictors respectively, where the predictors $X$ are simulated from a multivariate normal distribution $\text{MVN}_{n\times p}(0, I_{P})$. We then simulate the outcome $y$ from two distributions, Gaussian and binomial with the identity link and logit link $g(x) = \log(\frac{x}{1-x})$ respectively. The mean of each outcome were simulated via the following function
$$
\mathbb{E}(Y) = g^{-1}(5 \sin(2\pi x_1) - 4 \cos(2\pi x_2 -0.5) + 6(x_3-0.5) - 5(x_4^2 -0.3))
$$
for Gaussian and binomial outcomes.
<!-- and shrinked effects -->
<!-- $$ -->
<!-- \mathbb{E}(Y) = g^{-1}(\sin(2\pi x_1) - 2\cos(2\pi x_2 -0.5) + 0.4(x_3-0.5) - 2(x_4^2 -0.3)) -->
<!-- $$ -->
<!-- for  poisson outcomes.  -->
Gaussian outcomes requires specification of dispersion, where we set the dispersion parameter to be 1. In this data generating process, we have $x_1, x_2, x_3, x_4$ as the active covariates, while the rest covariates are inactive, i.e. $f_j(x_j) = 0$ for $j = 4, \dots, p$. Another set of independent sample of size $n_{test}=1000$, are created following the same data generating process, serving as the testing data. We generate 50 independent pairs of training and testing datasets to evaluate the prediction performance of the chosen models, where training datasets are used to fit the models and testing datasets used to calculate assessment measures.
<!-- The dimensional of the smoothing functions are controlled as k=10. Hence, the corresponding number of coefficient parameters to be estimated is 37, 82, 451 and 1801.  -->
<!-- We also run the simulation where the number of bases are increased to 25 deliberately. -->

To evaluate the predictive performance of the models, the statistics, $R^2$ for Gaussian model and AUC for binomial model calculated based on the testing dataset, are averaged <!--and deviance are calculated for Poisson model,--> across 50 simulations. Computation time for model selection, final model fitting and prediction are recorded for all simulations.


\begin{center}
Table \ref{tab:gaus} here\\
Table \ref{tab:bin_auc} here\\
\end{center}
```{r, fig.height=8, eval = FALSE}
targets::tar_load(binom_plot)
binom_plot
```


```{r, fig.height=8, eval = FALSE}
targets::tar_load(gaussian_plot)
gaussian_plot
```


```{r, fig.height=8, eval = FALSE}
targets::tar_load(poisson_plot)
poisson_plot
```

The predictive performances have a consistent pattern across the two distributions of outcomes. Across all the scenarios, COSSO and adaptive COSSO have the least favorable performance among the applicable methods examined (See Table \ref{tab:gaus} and \ref{tab:bin_auc}). To note, mgcv doesn't support high-dimensional analysis, i.e. the number of coefficients are greater than the sample size, and hence not evaluated when $p=100, 200$. mgcv predicts well when $p$ is small or moderate ($p = 4, 10$), and deteriorate when the number of predictors increase. Among the three fast-computing Bayesian hierarchical models, the proposed models, BHAM-IWLS and BHAM-CD predicts better than SB-GAM when the dimension of are moderate (p=4, 10, 50). Particularly, BHAM-IWLS performs as good as mgcv if not better. However, in high dimensional case where we mimic the situation the signals are extremely sparse, SB-GAM has better performance than the proposed method. However, the BHAM-CD has extreme computational advantage over SB-GAM (see Table \ref{tab:time_sim}) without sacrificing much of the prediction accuracy. 




<!-- %are calculated to assess out-of-sample estimation accuracy, -->

<!-- We also calculated the area under the curve (AUC) of the receiver operating characteristic curve for $y_{new}$. We will also visually display the estimated smooth function with the smooth function of truth to compare if the models can infer the smooth function correctly, despite the prediction accuracy. -->



<!-- The accuracy of variable selection is measured using Matthews correlation coefficient (MCC), -->
<!-- $$ -->
<!-- MCC = \frac{TP\times TN - FP \times FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}, -->
<!-- $$ -->
<!-- where TP, TN, FP, and FN are true positives, true negatives, false positives, and false negatives, respectively. -->


 \  

<!-- ### Simulation Results -->

<!-- Overall, the proposed priors outperforms the state-of-the-art GAM model `mgcv` when the dimensionality is low, median, and high. The proposed priors predicts better than `mgcv` and infers better of the underlying smooth function. Most importantly, `mgcv` is infeasible in the high dimensional setting, i.e. when $p=50$ where the number of parameters are greater than the sample size.  -->


<!-- #### Prediction Performace -->

<!-- The prediction performance is tabulated in the table below for AUC and Supplementary tables for MSE and misclassification rate. In summary, the proposed Bayesian models outperforms the benchmark model `mgcv` regardless the choice of prior or fitting algorithm. The models with IRLS fitting algorithm give slightly better performance than the the model with cyclic coordinate descent algorithm. The advantage diminishes in the high dimensional setting (p=50). This is possible because the SS normal spline prior provides a more smooth solution, which would work well in a low to median dimension setting. However, in the high dimensional setting, there are not enough sparsity in the model, i.e. SS normal prior will provides a more complex model than necessary. This is confirmed with the visualization in the following section.  -->

```{r tab.id="sim_GAM_AUC", eval=F}
glm_spline_pred_dat <-readr::read_rds("Simulation_Result/predict_res.rds")

glm_spline_pred_dat$auc %>% 
        select(-c(n_train, n_test, "bglm_t", "bglm_de", "blasso")) %>% 
        flextable() %>% 
  set_caption(caption = "Averaged AUC of out-of-bag samples",
              autonum = run_autonum(seq_id = "tab", bkm="sim_GAM_AUC", pre_label = "Table "))
```

```{r  eval=F}
glm_spline_pred_dat <-readr::read_rds("Simulation_Result/predict_res.rds")

glm_spline_pred_dat$misclass %>% 
        select(-c(n_train, n_test, "bglm_t", "bglm_de", "blasso")) %>% 
        flextable() %>% 
  set_caption(caption = "Averaged misclassification rate of out-of-bag samples",
              autonum = run_autonum(seq_id = "tab", bkm="sim_GAM_Misclass", pre_label = "Table "))
```


```{r  eval=F}

glm_spline_pred_dat <-readr::read_rds("Simulation_Result/predict_res.rds")

glm_spline_pred_dat$mse %>% 
        select(-c(n_train, n_test, "bglm_t", "bglm_de", "blasso")) %>% 
        flextable() %>% 
  set_caption(caption = "Averaged mean squared area of out-of-bag samples",
              autonum = run_autonum(seq_id = "tab", bkm="sim_GAM_MSE", pre_label = "Table "))
```

<!-- #### Visualization -->
<!-- We plot the estimated smooth functions of the four active variables for the 100 simulation iterations, along with the 'true' smooth function. Across different settings of predictors, the patterns look similar. First of all, in all the settings, `mgcv` tends to provide more  extreme models, where in the graphs the smooth function have much higher bound than the true smooth function. Rarely the estimated smooth function from `mgcv` matches with the true smooth function. In comparison, the proposed method can interpolate the shape of the true smooth function. However, different priors and fitting algorithms have different advantages. For example, in Figure 1, we see that the SS normal distribution have problem with the tail of the smooth function, especially obvious in the estimations of the variable _x4_. However, it would have less sparse solutions, which is more likely to accurately interpolate the smooth function especially when the shape is complicated (see variable _x2_). On the contrary, the SS double exponential prior model encourages sparse solutions, which can sometime omit active predictors. -->

