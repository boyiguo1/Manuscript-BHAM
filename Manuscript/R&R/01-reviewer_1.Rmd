We sincerely thank you for the valuable comments. We have carefully addressed all the comments. A point-by-point response is given below, where each of your comments is quoted in _italics_. __For a summary of major changes, please see our response to the Associate Editor.__

\bigskip

_Comments to the Authors_

_In this paper, the authors proposed a novel Bayesian hierarchical generalized additive model (BHAM) for high dimensional data analysis. Specifically, they incorporated smoothing penalties in the model via re-parameterization of smoothing function to avoid overly shrinking basis function coefficients. Incorporating the smoothing penalty allows the separation of the linear space of a smoothing function from the nonlinear space. Then they added a new two-part spike-and-slab spline prior on the smoothing functions for bi-level selection such that the linear and nonlinear spaces of smoothing functions can be selected separately. Two scalable optimization algorithms, EM-Coordinate Descent (EM-CD) algorithm and EM-Iterative weighted least square (EM-IWLS) algorithm, are developed and implemented._

_The proposed framework, BHAM, provides computational convenience using independent mixture double exponential distribution during model fitting by using optimization algorithms instead of intensive sampling algorithms and addresses the incapability of bi-level selection._

\bigskip

_Here are some comments._

_1. In the real data study, it is very important to establish the correlation between response variables and explanatory variables with appropriate models. The authors should add the comparison of linear models to illustrate that whether using non-linear was better. In addition, except expertise knowledge, are there metrics to judge whether a model is suitable for building model with non-linear part?_

__Response__: Thank you for the comment. We expanded our simulation study from two perspectives: 1) we added linear lasso models and spikeSlabGAM models, where linear lasso models serve as the reference to benchmark the performance of linear models; 2) we added new scenarios where the the functional form of each predictors are linear, to demonstrate the robustness of the proposed, regarding prediction and variable selection performances, when the non-linear assumption no longer holds. Please see the changes and conclusion in \emph{Section 3: SIMULATION STUDY}. To conclude, we observed [TODO: REPLACE HERE WITH CONCLUSION]. Hence, the proposed models perform better than linear models when functional are non-linear and as good as linear model when functions are linear. The expanded simulation study also demonstrates that the proposed model is flexible to model both linear and non-linear effects and broadly applicable in high-dimensional modeling without much constraints, which deems to be an additional strength.


\bigskip

_2. In Weight Loss Maintenance Cohort, R2 was very small by the two GAM methods.  I may think whether the data pretreatment and noise reduction process is appropriate._

__Response__: We thank the reviewer for the comment. We didn't perform the data processing step ourselves. We used the publicly available data that has been pre-processed. The data processing step is described in [TODO: add citation]. Meanwhile, we respectively argue that the small R2 is reasonable, as in many applications, genomics data can only accounts small amount of data variation. We think this example would be the case, as environmental factors (not accounted in these models) would be more substantial when explaining weight loss.
\bigskip

_3. In the paper, several priors were mentioned. How to choose the prior in different situations? What is the advantage of the spike-and-slab double exponential prior?_

__Response__: Thank you for the comment. The purpose of mentioning the other several priors in the previous manuscript is to describe the generalization of the proposed algorithms. In the updated manuscript, we move the subsection describing the other priors to the supporting information so that the readers can focus on understanding the proposed scalably model. We included an additional sentence in the discussion section. [TODO: list the sentence here].

Compared to other priors, the spike-and-slab double exponential prior provides three advantages. First of all, the spike-and-slab double exponential prior provides a locally adaptive shrinkage when estimating the coefficients. Hence, the smoothing functions can be estimated more accurately. Secondly, the spike-and-slab exponential prior encourages a sparse solution, making variable selection straight forward. Thirdly, the spike-and-slab double exponential prior motivates a scalable algorithm, the EM-CD algorithm, for model fitting, and hence is more feasible for high-dimensional data analysis.

We revised our method section to highlight these advantages, see Pxxx.


\bigskip

_4. How to detect the necessary before using the proposed model._

__Response__: We don't think any preliminary checkings or testings are necessary before implementing the proposed model, as long as some general rules of thumb for high-dimensional modeling are followed. Such rules of thumb includes [TODO: Insert citaiton for ultra high-dimension thing, as the number of predictors is a function of the sample size.]. As a supporting evidence, our added simulation demonstrates the proposed model performs well, in reference to the linear lasso model, even when signals are linear and sparse (see response to the Comment 1). 

We acknowledge the reviewer's comment that careful deliberation are necessary when conducting analysis, which includes domain knowledge. However, the discussion of modeling strategy, e.g. starting with more flexible models or linear models, or using statistical testings to examine assumptions, is out of the scope of the current manuscript. The current manuscript focuses on introducing a novel model that allows flexibility when modeling complex signals.
